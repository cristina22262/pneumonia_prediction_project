# -*- coding: utf-8 -*-
"""bigdl_transfer_learning_inception.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JMcih4nDzK1-5RfxNi_fS8Bp0TvIkrxi

# BigDL installation, Spark Session Creation and Loading Required Libraries
"""

!pip install --pre --upgrade bigdl-dllib-spark3

exit() # restart the runtime to refresh installed pkg

import os

from bigdl.dllib.nn.criterion import *
from bigdl.dllib.nn.layer import *
from bigdl.dllib.optim.optimizer import Adam
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.sql.functions import col, udf
from pyspark.sql.types import DoubleType, StringType

from bigdl.dllib.nncontext import *
from bigdl.dllib.feature.image import *
from bigdl.dllib.nnframes import *

from optparse import OptionParser

spark_conf = SparkConf().set("spark.driver.memory", "20g") \
            .set("spark.driver.cores", 6)
sc = init_nncontext(spark_conf, cluster_mode="local")

"""# Data Upload and Pre-processing"""

!pip install -q kaggle
from google.colab import drive
drive.mount('/content/drive')
from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!cat ~/.kaggle/kaggle.json
import kagglehub

from pyspark.sql.functions import lit
from pyspark.sql.types import StructType, StructField, StringType

imagepath = kagglehub.dataset_download("paultimothymooney/chest-xray-pneumonia")
import os
data_path = os.path.join(imagepath, 'chest_xray')
print(os.listdir(data_path))


train_path = os.path.join(data_path, 'train')
val_path = os.path.join(data_path, 'val')
test_path = os.path.join(data_path, 'test')

from pyspark.sql.functions import udf, col
from pyspark.sql.types import StringType
import os

pneumonia_path = os.path.join(train_path, 'PNEUMONIA')
normal_path = os.path.join(train_path, 'NORMAL')

# Read normal images and add a "label" column
imageDF_train_p = NNImageReader.readImages(pneumonia_path, sc, resizeH=300, resizeW=300, image_codec=1) \
    .withColumn("label", lit(2.0).cast(DoubleType()))  # Assign "pneumonia" as a '2' label

imageDF_train_n = NNImageReader.readImages(normal_path, sc, resizeH=300, resizeW=300, image_codec=1) \
    .withColumn("label", lit(1.0).cast(DoubleType()))  # Assign "normal" as a '1' label
# Combine both DataFrames
imageDF_train = imageDF_train_p.union(imageDF_train_n)
# for validation set
imageDF_val_p = NNImageReader.readImages(os.path.join(val_path, 'PNEUMONIA'), sc, resizeH=300, resizeW=300, image_codec=1) \
    .withColumn("label", lit(2.0).cast(DoubleType()))
imageDF_val_n = NNImageReader.readImages(os.path.join(val_path, 'NORMAL'), sc, resizeH=300, resizeW=300, image_codec=1) \
    .withColumn("label", lit(1.0).cast(DoubleType()))
imageDF_val = imageDF_val_p.union(imageDF_val_n)
# for test set
imageDF_test_p = NNImageReader.readImages(os.path.join(test_path, 'PNEUMONIA'), sc, resizeH=300, resizeW=300, image_codec=1) \
    .withColumn("label", lit(2.0).cast(DoubleType()))
imageDF_test_n = NNImageReader.readImages(os.path.join(test_path, 'NORMAL'), sc, resizeH=300, resizeW=300, image_codec=1) \
    .withColumn("label", lit(1.0).cast(DoubleType()))
imageDF_test = imageDF_test_p.union(imageDF_test_n)

imageDF_train.printSchema()

"""# Model and Pipeline Definition"""

batch_size = 56
nb_epoch = 20
learning_rate = 0.002

transformer = ChainedPreprocessing(
    [RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224),
    ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageFeatureToTensor()])


preTrainedNNModel = NNModel(Model.loadModel("/content/analytics-zoo_inception-v1_imagenet_0.1.0.model"), transformer) \
    .setFeaturesCol("image") \
    .setPredictionCol("embedding")

lrModel = Sequential().add(Linear(1000, 2)).add(LogSoftMax())

classifier = NNClassifier(lrModel, ClassNLLCriterion(), SeqToTensor([1000])) \
    .setLearningRate(learning_rate) \
    .setOptimMethod(Adam()) \
    .setBatchSize(batch_size) \
    .setMaxEpoch(nb_epoch) \
    .setFeaturesCol("embedding") \
    .setCachingSample(False) \

pipeline = Pipeline(stages=[preTrainedNNModel, classifier])

"""#Model training"""

model = pipeline.fit(imageDF_train)

"""#Validation and Prediction Error"""

predictionDF = model.transform(imageDF_val).cache()
predictionDF.sample(False, 0.1).show()

evaluator = MulticlassClassificationEvaluator(
        labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictionDF)
print("Validation Error = %g " % (1.0 - accuracy))

testDF = model.transform(imageDF_test).cache()
testDF.sample(False, 0.1).show()

evaluator = MulticlassClassificationEvaluator(
        labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(testDF)
print("Validation Error = %g " % (1.0 - accuracy))